{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Image Description Generator**:\n",
        "\n",
        "Build a tool that generates detailed, accurate text descriptions of uploaded images to improve accessibility.\n",
        "This tests their ability to integrate multimodal AI capabilities. (consider architecture pictures)"
      ],
      "metadata": {
        "id": "aH5iBE-0J1lj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from io import BytesIO\n",
        "import requests\n",
        "from PIL import Image\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "import torch\n",
        "\n",
        "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
        "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
        "\n",
        "def generate_caption(image_path):\n",
        "    if image_path.startswith(\"http\"):\n",
        "        headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "        response = requests.get(image_path, headers=headers, stream=True)\n",
        "        if response.status_code == 200 and \"image\" in response.headers.get(\"Content-Type\", \"\"):\n",
        "            image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "        else:\n",
        "            raise Exception(f\"Failed to download image, status code: {response.status_code}\")\n",
        "    else:\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "    inputs = processor(images=image, return_tensors=\"pt\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(\n",
        "            **inputs,\n",
        "            max_length=500,\n",
        "            num_beams=10,\n",
        "            repetition_penalty=2.5,      #Penalizes repetitive words in the caption.\n",
        "            do_sample=True,              #Enables randomness in text generation.\n",
        "            temperature=0.5,\n",
        "            top_k=50,                    #Selects the top 50 most likely words at each step to form the caption.\n",
        "            num_return_sequences=1,\n",
        "            decoder_start_token_id=model.config.bos_token_id    #Specifies where decoding starts.\n",
        "        )\n",
        "\n",
        "    return processor.decode(output[0], skip_special_tokens=True)   # Ensures that special model tokens (like [CLS] or [SEP]) are removed.\n",
        "\n",
        "image_url = \"https://images.unsplash.com/photo-1517649763962-0c623066013b\"\n",
        "\n",
        "try:\n",
        "    caption = generate_caption(image_url)\n",
        "    print(\"Generated Caption:\", caption)\n",
        "except Exception as e:\n",
        "    print(\"Error:\", e)"
      ],
      "metadata": {
        "id": "--3KuQdSCFv1",
        "outputId": "5ab07212-4470-4f34-f06c-bb573481c7b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Caption: there are many bicyclists riding down the road in a race\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install groq"
      ],
      "metadata": {
        "id": "htGhyriiC45s",
        "outputId": "3f0f0728-59dc-43e2-8e68-fa4c23b29eda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: groq in /usr/local/lib/python3.11/dist-packages (0.18.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.27.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "from groq import Groq\n",
        "\n",
        "from google.colab import userdata\n",
        "groq_api_key=userdata.get('groq_api_key')\n",
        "\n",
        "client = Groq(api_key=groq_api_key)\n",
        "\n",
        "def encode_image(image_path):\n",
        "    with open(image_path, \"rb\") as image_file:\n",
        "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
        "\n",
        "def generate_image_description(image_input):\n",
        "\n",
        "    if image_input.startswith(\"http\"):\n",
        "        image_data = {\"type\": \"image_url\", \"image_url\": {\"url\": image_input}}\n",
        "    else:\n",
        "        base64_image = encode_image(image_input)\n",
        "        image_data = {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}}\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"llama-3.2-11b-vision-preview\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"text\", \"text\": \"Describe the image.\"},\n",
        "                    image_data\n",
        "                ]\n",
        "            }\n",
        "        ],\n",
        "        temperature=0.7,\n",
        "        max_completion_tokens=512,\n",
        "        top_p=1,\n",
        "    )\n",
        "\n",
        "    return completion.choices[0].message.content\n",
        "\n",
        "image_input = \"https://www.cybermedian.com/wp-content/uploads/2022/02/0j3G8oZH4Yj5voOmG.png\"\n",
        "#image_input = \"cycles.png\"\n",
        "\n",
        "image_description = generate_image_description(image_input)\n",
        "print(\"Image Description:\", image_description)\n",
        "\n"
      ],
      "metadata": {
        "id": "PlwuOwTvdiUh",
        "outputId": "7e627dd5-35fb-40d7-f252-97cf6bccb2f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image Description: The image depicts a flowchart with multiple nodes and arrows, illustrating the process of navigating a route. The chart is divided into two columns, with the left column featuring seven yellow boxes containing text, including \"Start\", \"Vacuum On\", \"Scan Environment\", \"Generate Map and Location\", \"Plan Route\", \"Route\", and \"Vacuum On\". The right column also contains seven yellow boxes with text, including \"Follow route\", \"Finished Route\", \"Battery Low\", \"Vacuum Off\", \"Return power dock\", \"Power Off\", and \"End\".\n",
            "\n",
            "The chart's background is white, providing a clean and clear visual representation of the process. The flowchart appears to be a detailed guide for navigating a route, with various steps and conditions that determine the next action. The use of different colors and shapes adds visual interest and helps to distinguish between different parts of the process.\n",
            "\n",
            "Overall, the image effectively communicates the steps involved in navigating a route, making it easy to follow and understand. The flowchart's structure and design make it a useful tool for anyone who needs to navigate a route, whether it's in a physical or virtual environment.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}