{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Image Description Generator**:\n",
        "\n",
        "Build a tool that generates detailed, accurate text descriptions of uploaded images to improve accessibility.\n",
        "This tests their ability to integrate multimodal AI capabilities. (consider architecture pictures)"
      ],
      "metadata": {
        "id": "aH5iBE-0J1lj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "import torch\n",
        "\n",
        "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
        "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
        "\n",
        "def generate_caption(image_path):\n",
        "    if image_path.startswith(\"http\"):\n",
        "        headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "        response = requests.get(image_path, headers=headers, stream=True)\n",
        "        if response.status_code == 200 and \"image\" in response.headers.get(\"Content-Type\", \"\"):\n",
        "            image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "        else:\n",
        "            raise Exception(f\"Failed to download image, status code: {response.status_code}\")\n",
        "    else:\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "    inputs = processor(images=image, return_tensors=\"pt\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(\n",
        "            **inputs,\n",
        "            max_length=500,\n",
        "            num_beams=10,\n",
        "            repetition_penalty=2.5,\n",
        "            do_sample=True,\n",
        "            temperature=0.5,\n",
        "            top_k=50,\n",
        "            num_return_sequences=1,\n",
        "            decoder_start_token_id=model.config.bos_token_id\n",
        "        )\n",
        "\n",
        "    return processor.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "image_url = \"https://www.cybermedian.com/wp-content/uploads/2022/02/0j3G8oZH4Yj5voOmG.png\"\n",
        "\n",
        "try:\n",
        "    caption = generate_caption(image_url)\n",
        "    print(\"Generated Caption:\", caption)\n",
        "except Exception as e:\n",
        "    print(\"Error:\", e)\n"
      ],
      "metadata": {
        "id": "--3KuQdSCFv1",
        "outputId": "65b6187c-5bd7-45df-f625-d9817cf11a38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Caption: this is an image of a flow diagram that shows how to use the system\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install groq"
      ],
      "metadata": {
        "id": "htGhyriiC45s",
        "outputId": "dc0cacd7-9a86-4dd9-8438-f2eef19808ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: groq in /usr/local/lib/python3.11/dist-packages (0.18.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.27.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import base64\n",
        "from groq import Groq\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "groq_api_key=userdata.get('groq_api_key')\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = groq_api_key\n",
        "client = Groq()\n",
        "\n",
        "def encode_image(image_path):\n",
        "    with open(image_path, \"rb\") as image_file:\n",
        "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
        "\n",
        "def generate_image_description(image_input):\n",
        "\n",
        "    if image_input.startswith(\"http\"):\n",
        "        image_data = {\"type\": \"image_url\", \"image_url\": {\"url\": image_input}}\n",
        "    else:\n",
        "        base64_image = encode_image(image_input)\n",
        "        image_data = {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}}\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"llama-3.2-11b-vision-preview\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"text\", \"text\": \"Describe the image.\"},\n",
        "                    image_data\n",
        "                ]\n",
        "            }\n",
        "        ],\n",
        "        temperature=0.7,\n",
        "        max_completion_tokens=512,\n",
        "        top_p=1,\n",
        "    )\n",
        "\n",
        "    return completion.choices[0].message.content\n",
        "\n",
        "image_input = \"https://www.cybermedian.com/wp-content/uploads/2022/02/0j3G8oZH4Yj5voOmG.png\"\n",
        "#image_input = \"cycles.png\"\n",
        "\n",
        "image_description = generate_image_description(image_input)\n",
        "print(\"Image Description:\", image_description)\n",
        "\n"
      ],
      "metadata": {
        "id": "PlwuOwTvdiUh",
        "outputId": "c71496fa-9fbb-4658-c586-aff149931412",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image Description: The provided flowchart presents a complex process with multiple starting and ending points. The chart is divided into two sections: a flowchart on the left side and another on the right side. The left section features a traditional flowchart structure, comprising a series of boxes with arrows leading to subsequent steps. In contrast, the right section employs a more intricate approach, with arrows pointing to various boxes and flowchart sections, ultimately leading to the \"End\" box. \n",
            "\n",
            "The flowchart appears to be a part of a larger diagram, with the top-left corner featuring the word \"Start\" enclosed within a pink oval. However, the context of the flowchart itself is unclear, as the words and symbols employed are not recognizable. \n",
            "\n",
            "Despite the complexity of the flowchart, it is evident that the process involves multiple steps and decision-making points. The use of various symbols and arrows suggests a highly structured and organized process, but the specific purpose and context of the flowchart remain unclear. Overall, the image presents a visually striking and intricate diagram that demands attention and analysis.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}