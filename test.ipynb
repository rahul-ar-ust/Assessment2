{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Image Description Generator**:\n",
        "\n",
        "Build a tool that generates detailed, accurate text descriptions of uploaded images to improve accessibility.\n",
        "This tests their ability to integrate multimodal AI capabilities. (consider architecture pictures)"
      ],
      "metadata": {
        "id": "aH5iBE-0J1lj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "import torch\n",
        "\n",
        "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
        "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
        "\n",
        "def generate_caption(image_path):\n",
        "    if image_path.startswith(\"http\"):\n",
        "        headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "        response = requests.get(image_path, headers=headers, stream=True)\n",
        "        if response.status_code == 200 and \"image\" in response.headers.get(\"Content-Type\", \"\"):\n",
        "            image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "        else:\n",
        "            raise Exception(f\"Failed to download image, status code: {response.status_code}\")\n",
        "    else:\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "    inputs = processor(images=image, return_tensors=\"pt\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(\n",
        "            **inputs,\n",
        "            max_length=500,\n",
        "            num_beams=10,\n",
        "            repetition_penalty=2.5,\n",
        "            do_sample=True,\n",
        "            temperature=0.5,\n",
        "            top_k=50,\n",
        "            num_return_sequences=1,\n",
        "            decoder_start_token_id=model.config.bos_token_id\n",
        "        )\n",
        "\n",
        "    return processor.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "image_url = \"https://www.cybermedian.com/wp-content/uploads/2022/02/0j3G8oZH4Yj5voOmG.png\"\n",
        "\n",
        "try:\n",
        "    caption = generate_caption(image_url)\n",
        "    print(\"Generated Caption:\", caption)\n",
        "except Exception as e:\n",
        "    print(\"Error:\", e)\n"
      ],
      "metadata": {
        "id": "--3KuQdSCFv1",
        "outputId": "65b6187c-5bd7-45df-f625-d9817cf11a38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Caption: this is an image of a flow diagram that shows how to use the system\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install groq"
      ],
      "metadata": {
        "id": "htGhyriiC45s",
        "outputId": "dc0cacd7-9a86-4dd9-8438-f2eef19808ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: groq in /usr/local/lib/python3.11/dist-packages (0.18.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.27.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "from groq import Groq\n",
        "\n",
        "from google.colab import userdata\n",
        "groq_api_key=userdata.get('groq_api_key')\n",
        "\n",
        "client = Groq(api_key=groq_api_key)\n",
        "\n",
        "def encode_image(image_path):\n",
        "    with open(image_path, \"rb\") as image_file:\n",
        "        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
        "\n",
        "def generate_image_description(image_input):\n",
        "\n",
        "    if image_input.startswith(\"http\"):\n",
        "        image_data = {\"type\": \"image_url\", \"image_url\": {\"url\": image_input}}\n",
        "    else:\n",
        "        base64_image = encode_image(image_input)\n",
        "        image_data = {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}}\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"llama-3.2-11b-vision-preview\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"text\", \"text\": \"Describe the image.\"},\n",
        "                    image_data\n",
        "                ]\n",
        "            }\n",
        "        ],\n",
        "        temperature=0.7,\n",
        "        max_completion_tokens=512,\n",
        "        top_p=1,\n",
        "    )\n",
        "\n",
        "    return completion.choices[0].message.content\n",
        "\n",
        "image_input = \"https://www.cybermedian.com/wp-content/uploads/2022/02/0j3G8oZH4Yj5voOmG.png\"\n",
        "#image_input = \"cycles.png\"\n",
        "\n",
        "image_description = generate_image_description(image_input)\n",
        "print(\"Image Description:\", image_description)\n",
        "\n"
      ],
      "metadata": {
        "id": "PlwuOwTvdiUh",
        "outputId": "30189da8-5407-49b0-97b1-be089a9dda64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image Description: The image presents a flowchart that outlines the steps involved in navigating a route. The flowchart is divided into several sections, each representing a different stage in the process.\n",
            "\n",
            "* **Start**:\n",
            "\t+ The flowchart begins with a \"Start\" section, which is represented by a pink oval.\n",
            "\t+ This section serves as the starting point for the flowchart and initiates the process of navigating a route.\n",
            "* **Power On**:\n",
            "\t+ The next section is \"Power On,\" which is represented by a yellow rectangle with a blue background.\n",
            "\t+ This section indicates that the device has been turned on, and the system is ready to begin the route navigation process.\n",
            "* **Scan Environment**:\n",
            "\t+ The following section is \"Scan Environment,\" which is represented by a yellow rectangle with a blue background.\n",
            "\t+ This section suggests that the device is scanning its surroundings to gather information about the environment.\n",
            "* **Generate Map and Location**:\n",
            "\t+ The next section is \"Generate Map and Location,\" which is represented by a yellow rectangle with a blue background.\n",
            "\t+ This section implies that the device is generating a map of the area and determining its location.\n",
            "* **Plan Route**:\n",
            "\t+ The following section is \"Plan Route,\" which is represented by a yellow rectangle with a blue background.\n",
            "\t+ This section indicates that the device is planning the route, taking into account the information gathered from the previous steps.\n",
            "* **Route**:\n",
            "\t+ The next section is \"Route,\" which is represented by a yellow rectangle with a blue background.\n",
            "\t+ This section represents the actual route that the device will follow.\n",
            "* **Follow Route**:\n",
            "\t+ The following section is \"Follow Route,\" which is represented by a yellow rectangle with a blue background.\n",
            "\t+ This section indicates that the device is following the planned route.\n",
            "* **Vacuum On**:\n",
            "\t+ The next section is \"Vacuum On,\" which is represented by a yellow rectangle with a blue background.\n",
            "\t+ This section suggests that the device is turning on its vacuum function.\n",
            "* **Return Power Dock**:\n",
            "\t+ The following section is \"Return Power Dock,\" which is represented by a yellow rectangle with a blue background.\n",
            "\t+ This section indicates that the device is returning to its power dock.\n",
            "* **End**:\n",
            "\t+ The final section is \"End,\" which is represented by a pink oval.\n",
            "\t+ This section marks the end of the flowchart and indicates that the process is complete.\n",
            "\n",
            "In summary, the flowchart outlines the steps involved in navigating\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}